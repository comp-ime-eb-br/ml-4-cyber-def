{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score,roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks,layers\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_assemble(path, test_size=0.3):\n",
    "    # Import dataset\n",
    "    df_dataset = pd.read_csv(path)\n",
    "\n",
    "    # Encode Labels for numeric classification\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_dataset['Label'] = label_encoder.fit_transform(df_dataset['Label'])\n",
    "\n",
    "    # Set a random state for sampling\n",
    "    RANDOM_STATE_SEED = np.random.randint(123)\n",
    "    print(f'Random Seed:{RANDOM_STATE_SEED}')\n",
    "    \n",
    "    # Split dataset in train and test\n",
    "    train, test = train_test_split(df_dataset, test_size=test_size, random_state=RANDOM_STATE_SEED)\n",
    "    \n",
    "    # Count how many instances there are in each label\n",
    "    print(df_dataset[\"Label\"].value_counts())\n",
    "\n",
    "    # Separate in X and y for better classification\n",
    "    y_train = np.array(train.pop(\"Label\"))# pop removes \"Label\" from the dataframe\n",
    "    X_train = train.values\n",
    "\n",
    "    print(f'Tipo X_train: {type(X_train)} Tipo y_train: {type(y_train)} Shape X_train:{X_train.shape} Shape y_train: {y_train.shape}')\n",
    "\n",
    "    y_test = np.array(test.pop(\"Label\")) # pop removes \"Label\" from the dataframe\n",
    "    X_test = test.values\n",
    "\n",
    "    print(f'Tipo X_test: {type(X_test)} Tipo y_test: {type(y_test)} Shape X_test:{X_test.shape} Shape y_test: {y_test.shape}')\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_assemble(X_train):\n",
    "    models = {}\n",
    "\n",
    "    models['DT'] = DecisionTreeClassifier()\n",
    "    models['RF'] = RandomForestClassifier()\n",
    "    models['SVM'] = LinearSVC(max_iter=10000, dual=False,)\n",
    "    models['KNN'] = KNeighborsClassifier()\n",
    "    models['NB'] = GaussianNB()\n",
    "    models['XGB'] = xgb.XGBClassifier()\n",
    "    models['NN'] = keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "            \n",
    "            layers.BatchNormalization(renorm=True),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(rate = 0.3),\n",
    "            layers.BatchNormalization(renorm=True),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(rate = 0.3),\n",
    "            layers.BatchNormalization(renorm=True),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dropout(rate = 0.3),\n",
    "            layers.Dense(1, activation='sigmoid'),\n",
    "        ])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grids_assemble(cv=2, model=None,key=None):\n",
    "    \n",
    "    hyperparameters = {}\n",
    "    hyperparameters['XGB'] = {'learning_rate': [0.9, 0.7, 0.5, 0.3, 0.1], 'n_estimators': [50,100,150,200],\n",
    "                              }\n",
    "    hyperparameters['DT'] = {'criterion': ['gini','entropy'], 'max_depth': [10,15,20,25,30],'splitter':['best','random']\n",
    "                             }\n",
    "    hyperparameters['RF'] = {'n_estimators': [50, 75, 100, 125, 150], 'criterion': ['gini','entropy'],'max_depth': [25,30]\n",
    "                             }\n",
    "    hyperparameters['SVM'] = { 'C': np.linspace(0.01,100, num=20)\n",
    "                              }\n",
    "    hyperparameters['NB'] = {'var_smoothing': np.logspace(0,-9, num=20)\n",
    "                             }\n",
    "    hyperparameters['KNN'] = {'n_neighbors': [8,9,10,11,12], 'weights': ['uniform','distance'], 'leaf_size': [10,100]\n",
    "                            }\n",
    "    hyperparameters['NN'] = {'epochs': [10,20], 'batch_size': [32,64,128,256,512], 'epsilon': [0.01,0.1]\n",
    "                            }\n",
    "\n",
    "    classifierGRID = GridSearchCV(\n",
    "        estimator = model,\n",
    "        param_grid = hyperparameters[key],\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "    return classifierGRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_assemble(classifierGRID,X_train,y_train):\n",
    "    classifierGRID.fit(X=X_train, y=y_train)\n",
    "\n",
    "    # Print best parameters found on GridsearchCV\n",
    "    print(\"Accuracy score on Validation set: \\n\")\n",
    "    print(classifierGRID.best_score_ )\n",
    "    print(\"---------------\")\n",
    "    print(\"Best performing hyperparameters on Validation set: \")\n",
    "    print(classifierGRID.best_estimator_)\n",
    "    print(\"---------------\")\n",
    "    \n",
    "\n",
    "\n",
    "    fitted_model = classifierGRID.best_estimator_\n",
    "    \n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNet_fit(neuralNetModel,X_train,y_train,epochs=10):\n",
    "    # %%\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
    "\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        min_delta = 0.001,\n",
    "        patience = 5,\n",
    "        restore_best_weights = True,\n",
    "        monitor= 'loss'\n",
    "    )\n",
    "\n",
    "\n",
    "    neuralNetModel.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy'],\n",
    "    )\n",
    "\n",
    "    history = neuralNetModel.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size = 256,\n",
    "        callbacks=[early_stopping]\n",
    "\n",
    "    )\n",
    "\n",
    "    return neuralNetModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_assemble(fitted_model,X_test,y_test):\n",
    "    \n",
    "    predictions = fitted_model.predict(X_test)\n",
    "\n",
    "    if predictions.dtype == 'float32':\n",
    "        predictions = (fitted_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(y_test,predictions)\n",
    "    precision = precision_score(y_test,predictions)\n",
    "    recall = recall_score(y_test,predictions)\n",
    "    f1= f1_score(y_test,predictions)\n",
    "    auc= roc_auc_score(y_test,predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:117\n",
      "Label\n",
      "1    67297\n",
      "0    58026\n",
      "Name: count, dtype: int64\n",
      "Tipo X_train: <class 'numpy.ndarray'> Tipo y_train: <class 'numpy.ndarray'> Shape X_train:(87726, 38) Shape y_train: (87726,)\n",
      "Tipo X_test: <class 'numpy.ndarray'> Tipo y_test: <class 'numpy.ndarray'> Shape X_test:(37597, 38) Shape y_test: (37597,)\n",
      "Epoch 1/100\n",
      "343/343 [==============================] - 4s 6ms/step - loss: 0.3346 - binary_accuracy: 0.8591\n",
      "Epoch 2/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.1224 - binary_accuracy: 0.9598\n",
      "Epoch 3/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0887 - binary_accuracy: 0.9685\n",
      "Epoch 4/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0680 - binary_accuracy: 0.9742\n",
      "Epoch 5/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0564 - binary_accuracy: 0.9803\n",
      "Epoch 6/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0469 - binary_accuracy: 0.9833\n",
      "Epoch 7/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0434 - binary_accuracy: 0.9845\n",
      "Epoch 8/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0393 - binary_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0374 - binary_accuracy: 0.9868\n",
      "Epoch 10/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0359 - binary_accuracy: 0.9870\n",
      "Epoch 11/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0348 - binary_accuracy: 0.9874\n",
      "Epoch 12/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0332 - binary_accuracy: 0.9878\n",
      "Epoch 13/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0320 - binary_accuracy: 0.9881\n",
      "Epoch 14/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0308 - binary_accuracy: 0.9889\n",
      "Epoch 15/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0301 - binary_accuracy: 0.9891\n",
      "Epoch 16/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0283 - binary_accuracy: 0.9896\n",
      "Epoch 17/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0294 - binary_accuracy: 0.9893\n",
      "Epoch 18/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0277 - binary_accuracy: 0.9895\n",
      "Epoch 19/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0277 - binary_accuracy: 0.9900\n",
      "Epoch 20/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0269 - binary_accuracy: 0.9898\n",
      "Epoch 21/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0256 - binary_accuracy: 0.9906\n",
      "Epoch 22/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0250 - binary_accuracy: 0.9907\n",
      "Epoch 23/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0249 - binary_accuracy: 0.9911\n",
      "Epoch 24/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0238 - binary_accuracy: 0.9914\n",
      "Epoch 25/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0234 - binary_accuracy: 0.9919\n",
      "Epoch 26/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0229 - binary_accuracy: 0.9921\n",
      "Epoch 27/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0223 - binary_accuracy: 0.9921\n",
      "Epoch 28/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0225 - binary_accuracy: 0.9924\n",
      "Epoch 29/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0222 - binary_accuracy: 0.9919\n",
      "Epoch 30/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0211 - binary_accuracy: 0.9928\n",
      "Epoch 31/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0216 - binary_accuracy: 0.9929\n",
      "Epoch 32/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0211 - binary_accuracy: 0.9928\n",
      "Epoch 33/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0197 - binary_accuracy: 0.9931\n",
      "Epoch 34/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0196 - binary_accuracy: 0.9932\n",
      "Epoch 35/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0195 - binary_accuracy: 0.9936\n",
      "Epoch 36/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0199 - binary_accuracy: 0.9932\n",
      "Epoch 37/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0198 - binary_accuracy: 0.9933\n",
      "Epoch 38/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0187 - binary_accuracy: 0.9937\n",
      "Epoch 39/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0184 - binary_accuracy: 0.9937\n",
      "Epoch 40/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0178 - binary_accuracy: 0.9939\n",
      "Epoch 41/100\n",
      "343/343 [==============================] - 2s 6ms/step - loss: 0.0183 - binary_accuracy: 0.9936\n",
      "Epoch 42/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0190 - binary_accuracy: 0.9939\n",
      "Epoch 43/100\n",
      "343/343 [==============================] - 2s 5ms/step - loss: 0.0182 - binary_accuracy: 0.9939\n",
      "1175/1175 [==============================] - 1s 1ms/step\n",
      "1175/1175 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC-Score</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Evaluation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.995186</td>\n",
       "      <td>0.994919</td>\n",
       "      <td>0.996147</td>\n",
       "      <td>0.995533</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>83.257947</td>\n",
       "      <td>4.445962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Precision    Recall  F1-Score  ROC-AUC-Score      Tempo   \n",
       "NN  0.995186   0.994919  0.996147  0.995533       0.995106  83.257947  \\\n",
       "\n",
       "    Evaluation Time  \n",
       "NN         4.445962  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define path to the dataset\n",
    "path = '/home/mintssj/Downloads/datasets/filtered/NSL_KDD_equal.csv'\n",
    "\n",
    "# Start dictionaries to store metrics\n",
    "accuracy, precision, recall, f1, auc, fit_time, eval_time, fitted_models = {}, {}, {}, {}, {}, {}, {}, {} \n",
    "\n",
    "# Get dataset splits for tranning and evaluation\n",
    "X_train,y_train,X_test,y_test = splits_assemble(path, test_size=0.3)\n",
    "\n",
    "# Start dictionary for models\n",
    "models=models_assemble(X_train)\n",
    "\n",
    "# # Start iteration loop for fitting and evaluating the classic models\n",
    "# for key in ['DT', 'RF', 'XGB', 'KNN', 'SVM', 'NB']:\n",
    "    \n",
    "#     # Get the grid of hyperparameters and start the GridsearchCV function\n",
    "#     classifierGRID = grids_assemble(cv=5, model=models[key],key=key)\n",
    "\n",
    "#     print(f'Fitting {key} model')\n",
    "\n",
    "#     # Fit model\n",
    "#     start_time = time.time()\n",
    "#     fitted_models[key] = fit_assemble(classifierGRID,X_train,y_train)\n",
    "#     end_time = time.time()\n",
    "#     fit_time[key] = end_time - start_time\n",
    "\n",
    "#     # Evaluate model\n",
    "#     start_time = time.time()\n",
    "#     accuracy[key], precision[key], recall[key], f1[key], auc[key] = metrics_assemble(fitted_models[key],X_test,y_test)\n",
    "#     end_time = time.time()\n",
    "#     eval_time[key] = end_time - start_time\n",
    "\n",
    "# Fit the neural network model\n",
    "start_time = time.time()\n",
    "neuralNetModel = NeuralNet_fit(models['NN'],X_train,y_train,epochs=100)\n",
    "end_time = time.time()\n",
    "fit_time['NN'] = end_time - start_time\n",
    "\n",
    "# Evaluate the neural network model\n",
    "start_time = time.time()\n",
    "accuracy['NN'], precision['NN'], recall['NN'], f1['NN'], auc['NN'] = metrics_assemble(neuralNetModel,X_test,y_test)\n",
    "end_time = time.time()\n",
    "eval_time['NN'] = end_time - start_time\n",
    "\n",
    "# Convert the metrics dictionaries into a dataframe for better visualization\n",
    "metrics = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score':f1, 'ROC-AUC-Score': auc, \\\n",
    "           'Tempo':fit_time, 'Evaluation Time':eval_time}\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "display(df_metrics)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
